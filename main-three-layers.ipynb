{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM-arithmetic\n",
    "\n",
    "## Dataset\n",
    "- [Arithmetic dataset](https://drive.google.com/file/d/1cMuL3hF9jefka9RyF4gEBIGGeFGZYHE-/view?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in c:\\github\\nthu-nlp-hw2-arithmetic-113061638\\.conda\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: opencc in c:\\github\\nthu-nlp-hw2-arithmetic-113061638\\.conda\\lib\\site-packages (1.1.9)\n",
      "Requirement already satisfied: matplotlib in c:\\github\\nthu-nlp-hw2-arithmetic-113061638\\.conda\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\github\\nthu-nlp-hw2-arithmetic-113061638\\.conda\\lib\\site-packages (1.5.2)\n",
      "Requirement already satisfied: tqdm in c:\\github\\nthu-nlp-hw2-arithmetic-113061638\\.conda\\lib\\site-packages (4.67.0)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\github\\nthu-nlp-hw2-arithmetic-113061638\\.conda\\lib\\site-packages (from seaborn) (2.1.3)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\github\\nthu-nlp-hw2-arithmetic-113061638\\.conda\\lib\\site-packages (from seaborn) (2.2.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\github\\nthu-nlp-hw2-arithmetic-113061638\\.conda\\lib\\site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\github\\nthu-nlp-hw2-arithmetic-113061638\\.conda\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\github\\nthu-nlp-hw2-arithmetic-113061638\\.conda\\lib\\site-packages (from matplotlib) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\github\\nthu-nlp-hw2-arithmetic-113061638\\.conda\\lib\\site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\github\\nthu-nlp-hw2-arithmetic-113061638\\.conda\\lib\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\github\\nthu-nlp-hw2-arithmetic-113061638\\.conda\\lib\\site-packages (from matplotlib) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\github\\nthu-nlp-hw2-arithmetic-113061638\\.conda\\lib\\site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\github\\nthu-nlp-hw2-arithmetic-113061638\\.conda\\lib\\site-packages (from matplotlib) (2.9.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\github\\nthu-nlp-hw2-arithmetic-113061638\\.conda\\lib\\site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\github\\nthu-nlp-hw2-arithmetic-113061638\\.conda\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\github\\nthu-nlp-hw2-arithmetic-113061638\\.conda\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: colorama in c:\\github\\nthu-nlp-hw2-arithmetic-113061638\\.conda\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\github\\nthu-nlp-hw2-arithmetic-113061638\\.conda\\lib\\site-packages (from pandas>=1.2->seaborn) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\github\\nthu-nlp-hw2-arithmetic-113061638\\.conda\\lib\\site-packages (from pandas>=1.2->seaborn) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\github\\nthu-nlp-hw2-arithmetic-113061638\\.conda\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install seaborn opencc matplotlib scikit-learn tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install seaborn\n",
    "# ! pip install opencc\n",
    "# ! pip install -U scikit-learn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn\n",
    "import torch.nn.utils.rnn\n",
    "import torch.utils.data\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import opencc\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_path = './data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>src</th>\n",
       "      <th>tgt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2285313</td>\n",
       "      <td>14*(43+20)=</td>\n",
       "      <td>882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>317061</td>\n",
       "      <td>(6+1)*5=</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>718770</td>\n",
       "      <td>13+32+29=</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>170195</td>\n",
       "      <td>31*(3-11)=</td>\n",
       "      <td>-248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2581417</td>\n",
       "      <td>24*49+1=</td>\n",
       "      <td>1177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0          src   tgt\n",
       "0     2285313  14*(43+20)=   882\n",
       "1      317061     (6+1)*5=    35\n",
       "2      718770    13+32+29=    74\n",
       "3      170195   31*(3-11)=  -248\n",
       "4     2581417     24*49+1=  1177"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(os.path.join(data_path, 'arithmetic_train.csv'))\n",
    "df_eval = pd.read_csv(os.path.join(data_path, 'arithmetic_eval.csv'))\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the input data to string\n",
    "df_train['tgt'] = df_train['tgt'].apply(lambda x: str(x))\n",
    "df_train['src'] = df_train['src'].add(df_train['tgt'])\n",
    "df_train['len'] = df_train['src'].apply(lambda x: len(x))\n",
    "\n",
    "df_eval['tgt'] = df_eval['tgt'].apply(lambda x: str(x))\n",
    "df_eval['src'] = df_eval['src'].add(df_eval['tgt'])\n",
    "df_eval['len'] = df_eval['src'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Dictionary\n",
    " - The model cannot perform calculations directly with plain text.\n",
    " - Convert all text (numbers/symbols) into numerical representations.\n",
    " - Special tokens\n",
    "    - '&lt;pad&gt;'\n",
    "        - Each sentence within a batch may have different lengths.\n",
    "        - The length is padded with '&lt;pad&gt;' to match the longest sentence in the batch.\n",
    "    - '&lt;eos&gt;'\n",
    "        - Specifies the end of the generated sequence.\n",
    "        - Without '&lt;eos&gt;', the model will not know when to stop generating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 18\n"
     ]
    }
   ],
   "source": [
    "char_to_id = {}\n",
    "id_to_char = {}\n",
    "\n",
    "# Add special tokens first\n",
    "char_to_id['<pad>'] = 0  \n",
    "char_to_id['<eos>'] = 1\n",
    "\n",
    "# Add common characters from expressions\n",
    "chars = set()\n",
    "for row in df_train['src'].values:\n",
    "    chars.update(list(row))\n",
    "\n",
    "# Sort chars to ensure consistent ordering\n",
    "sorted_chars = sorted(list(chars))\n",
    "for char in sorted_chars:\n",
    "    if char not in char_to_id:\n",
    "        idx = len(char_to_id)\n",
    "        char_to_id[char] = idx\n",
    "\n",
    "# Create reverse mapping\n",
    "for char, idx in char_to_id.items():\n",
    "    id_to_char[idx] = char\n",
    "\n",
    "vocab_size = len(char_to_id)\n",
    "print(f'Vocab size: {vocab_size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    " - The data is processed into the format required for the model's input and output.\n",
    " - Example: 1+2-3=0\n",
    "     - Model input: 1 + 2 - 3 = 0\n",
    "     - Model output: / / / / / 0 &lt;eos&gt;  (the '/' can be replaced with &lt;pad&gt;)\n",
    "     - The key for the model's output is that the model does not need to predict the next character of the previous part. What matters is that once the model sees '=', it should start generating the answer, which is '0'. After generating the answer, it should also generate&lt;eos&gt;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>src</th>\n",
       "      <th>tgt</th>\n",
       "      <th>len</th>\n",
       "      <th>char_id_list</th>\n",
       "      <th>label_id_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2285313</td>\n",
       "      <td>14*(43+20)=882</td>\n",
       "      <td>882</td>\n",
       "      <td>14</td>\n",
       "      <td>[8, 11, 4, 2, 11, 10, 5, 9, 7, 3, 17, 15, 15, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 15, 15, 9, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>317061</td>\n",
       "      <td>(6+1)*5=35</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>[2, 13, 5, 8, 3, 4, 12, 17, 10, 12, 1]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 10, 12, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>718770</td>\n",
       "      <td>13+32+29=74</td>\n",
       "      <td>74</td>\n",
       "      <td>11</td>\n",
       "      <td>[8, 10, 5, 10, 9, 5, 9, 16, 17, 14, 11, 1]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 14, 11, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>170195</td>\n",
       "      <td>31*(3-11)=-248</td>\n",
       "      <td>-248</td>\n",
       "      <td>14</td>\n",
       "      <td>[10, 8, 4, 2, 10, 6, 8, 8, 3, 17, 6, 9, 11, 15...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 9, 11, 15, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2581417</td>\n",
       "      <td>24*49+1=1177</td>\n",
       "      <td>1177</td>\n",
       "      <td>12</td>\n",
       "      <td>[9, 11, 4, 11, 16, 5, 8, 17, 8, 8, 14, 14, 1]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 8, 8, 14, 14, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0             src   tgt  len  \\\n",
       "0     2285313  14*(43+20)=882   882   14   \n",
       "1      317061      (6+1)*5=35    35   10   \n",
       "2      718770     13+32+29=74    74   11   \n",
       "3      170195  31*(3-11)=-248  -248   14   \n",
       "4     2581417    24*49+1=1177  1177   12   \n",
       "\n",
       "                                        char_id_list  \\\n",
       "0  [8, 11, 4, 2, 11, 10, 5, 9, 7, 3, 17, 15, 15, ...   \n",
       "1             [2, 13, 5, 8, 3, 4, 12, 17, 10, 12, 1]   \n",
       "2         [8, 10, 5, 10, 9, 5, 9, 16, 17, 14, 11, 1]   \n",
       "3  [10, 8, 4, 2, 10, 6, 8, 8, 3, 17, 6, 9, 11, 15...   \n",
       "4      [9, 11, 4, 11, 16, 5, 8, 17, 8, 8, 14, 14, 1]   \n",
       "\n",
       "                                  label_id_list  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 15, 15, 9, 1]  \n",
       "1              [0, 0, 0, 0, 0, 0, 0, 10, 12, 1]  \n",
       "2           [0, 0, 0, 0, 0, 0, 0, 0, 14, 11, 1]  \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 9, 11, 15, 1]  \n",
       "4        [0, 0, 0, 0, 0, 0, 0, 8, 8, 14, 14, 1]  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_sequence(df):\n",
    "    df['char_id_list'] = df['src'].apply(lambda x: [char_to_id[c] for c in x] + [char_to_id['<eos>']])\n",
    "    \n",
    "    # For each sequence, create label list with <pad> before '=' and actual digits after\n",
    "    def create_label_sequence(row):\n",
    "        # Find index of '=' in the input sequence\n",
    "        eq_idx = row['src'].find('=')\n",
    "        # Before = should be <pad>\n",
    "        prefix = [char_to_id['<pad>']] * eq_idx\n",
    "        # After = should be target number + <eos>\n",
    "        suffix = [char_to_id[c] for c in row['tgt']] + [char_to_id['<eos>']]\n",
    "        return prefix + suffix\n",
    "    \n",
    "    df['label_id_list'] = df.apply(create_label_sequence, axis=1)\n",
    "    return df\n",
    "\n",
    "df_train = preprocess_sequence(df_train) \n",
    "df_eval = preprocess_sequence(df_eval)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper Parameters\n",
    "\n",
    "|Hyperparameter|Meaning|Value|\n",
    "|-|-|-|\n",
    "|`batch_size`|Number of data samples in a single batch|64|\n",
    "|`epochs`|Total number of epochs to train|10|\n",
    "|`embed_dim`|Dimension of the word embeddings|256|\n",
    "|`hidden_dim`|Dimension of the hidden state in each timestep of the LSTM|256|\n",
    "|`lr`|Learning Rate|0.001|\n",
    "|`grad_clip`|To prevent gradient explosion in RNNs, restrict the gradient range|1|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "epochs = 10\n",
    "embed_dim = 512\n",
    "hidden_dim = 512\n",
    "lr = 0.001\n",
    "grad_clip = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Batching\n",
    "- Use `torch.utils.data.Dataset` to create a data generation tool called  `dataset`.\n",
    "- The, use `torch.utils.data.DataLoader` to randomly sample from the `dataset` and group the samples into batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, sequences):\n",
    "        self.sequences = sequences\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        x = self.sequences.iloc[index]['char_id_list']\n",
    "        y = self.sequences.iloc[index]['label_id_list']\n",
    "        return x, y\n",
    "\n",
    "# collate function, used to build dataloader\n",
    "def collate_fn(batch):\n",
    "    batch_x = [torch.tensor(data[0]) for data in batch]\n",
    "    batch_y = [torch.tensor(data[1]) for data in batch]\n",
    "    batch_x_lens = torch.LongTensor([len(x) for x in batch_x])\n",
    "    batch_y_lens = torch.LongTensor([len(y) for y in batch_y])\n",
    "    \n",
    "    # Pad the input sequence\n",
    "    pad_batch_x = torch.nn.utils.rnn.pad_sequence(batch_x,\n",
    "                                                  batch_first=True,\n",
    "                                                  padding_value=char_to_id['<pad>'])\n",
    "    \n",
    "    pad_batch_y = torch.nn.utils.rnn.pad_sequence(batch_y,\n",
    "                                                  batch_first=True,\n",
    "                                                  padding_value=char_to_id['<pad>'])\n",
    "    \n",
    "    return pad_batch_x, pad_batch_y, batch_x_lens, batch_y_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = Dataset(df_train[['char_id_list', 'label_id_list']])\n",
    "ds_eval = Dataset(df_eval[['char_id_list', 'label_id_list']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build dataloader of train set and eval set, collate_fn is the collate function\n",
    "# Create dataloaders\n",
    "dl_train = torch.utils.data.DataLoader(\n",
    "    ds_train, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "dl_eval = torch.utils.data.DataLoader(\n",
    "    ds_eval,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Design\n",
    "\n",
    "## Execution Flow\n",
    "1. Convert all characters in the sentence into embeddings.\n",
    "2. Pass the embeddings through an LSTM sequentially.\n",
    "3. The output of the LSTM is passed into another LSTM, and additional layers can be added.\n",
    "4. The output from all time steps of the final LSTM is passed through a Fully Connected layer.\n",
    "5. The character corresponding to the maximum value across all output dimensions is selected as the next character.\n",
    "\n",
    "## Loss Function\n",
    "Since this is a classification task, Cross Entropy is used as the loss function.\n",
    "\n",
    "## Gradient Update\n",
    "Adam algorithm is used for gradient updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharRNN(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim):\n",
    "        super(CharRNN, self).__init__()\n",
    "        \n",
    "        self.embedding = torch.nn.Embedding(num_embeddings=vocab_size,\n",
    "                                         embedding_dim=embed_dim,\n",
    "                                         padding_idx=char_to_id['<pad>'])\n",
    "        \n",
    "        self.rnn_layer1 = torch.nn.LSTM(input_size=embed_dim,\n",
    "                                      hidden_size=hidden_dim,\n",
    "                                      batch_first=True)\n",
    "        \n",
    "        self.rnn_layer2 = torch.nn.LSTM(input_size=hidden_dim,\n",
    "                                      hidden_size=hidden_dim,\n",
    "                                      batch_first=True)\n",
    "        \n",
    "        self.rnn_layer3 = torch.nn.LSTM(input_size=hidden_dim,\n",
    "                                        hidden_size=hidden_dim,\n",
    "                                        batch_first=True)\n",
    "        \n",
    "        self.linear = torch.nn.Sequential(\n",
    "            torch.nn.Linear(in_features=hidden_dim, out_features=hidden_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(in_features=hidden_dim, out_features=vocab_size)\n",
    "        )\n",
    "        \n",
    "    def forward(self, batch_x, batch_x_lens):\n",
    "        return self.encoder(batch_x, batch_x_lens)\n",
    "    \n",
    "    def encoder(self, x, x_lens):\n",
    "        # 確保輸入是二維的 [batch_size, seq_len]\n",
    "        if len(x.shape) == 1:\n",
    "            x = x.unsqueeze(0)\n",
    "        if not isinstance(x_lens, torch.Tensor):\n",
    "            x_lens = torch.tensor([x_lens])\n",
    "        if len(x_lens.shape) == 0:\n",
    "            x_lens = x_lens.unsqueeze(0)\n",
    "            \n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        x = torch.nn.utils.rnn.pack_padded_sequence(\n",
    "            x,\n",
    "            x_lens.cpu(),\n",
    "            batch_first=True,\n",
    "            enforce_sorted=False\n",
    "        )\n",
    "        \n",
    "        x, _ = self.rnn_layer1(x)\n",
    "        x, _ = self.rnn_layer2(x)\n",
    "        x, _ = self.rnn_layer3(x)\n",
    "        \n",
    "        x, _ = torch.nn.utils.rnn.pad_packed_sequence(\n",
    "            x,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "    def generator(self, expression, max_len=200):\n",
    "        \"\"\"\n",
    "        Improved generator that handles a single expression\n",
    "        \n",
    "        Args:\n",
    "            expression: String containing the expression to evaluate\n",
    "            max_len: Maximum length of generated sequence\n",
    "        \"\"\"\n",
    "        device = next(self.parameters()).device\n",
    "        \n",
    "        # Find position of equals sign\n",
    "        eq_position = expression.find('=')\n",
    "        if eq_position == -1:\n",
    "            return expression\n",
    "            \n",
    "        # Convert expression to character IDs\n",
    "        char_ids = [char_to_id[c] for c in expression]\n",
    "        current_position = eq_position + 1\n",
    "        \n",
    "        # Initialize the input tensor\n",
    "        x = torch.tensor(char_ids, device=device)\n",
    "        x = x.unsqueeze(0)  # Add batch dimension\n",
    "        \n",
    "        # Generate the answer\n",
    "        generated_chars = []\n",
    "        \n",
    "        while current_position < max_len:\n",
    "            with torch.no_grad():\n",
    "                # Get model output\n",
    "                x_len = torch.tensor([len(x[0])], device=device)\n",
    "                output = self.encoder(x, x_len)\n",
    "                \n",
    "                # Get next character prediction\n",
    "                logits = output[0, current_position - 1]\n",
    "                next_char = torch.argmax(logits).item()\n",
    "                \n",
    "                # Check for end of sequence\n",
    "                if next_char == char_to_id['<eos>']:\n",
    "                    break\n",
    "                    \n",
    "                # Add to generated sequence\n",
    "                generated_chars.append(next_char)\n",
    "                \n",
    "                # Update input for next iteration\n",
    "                if current_position < len(x[0]):\n",
    "                    x[0, current_position] = next_char\n",
    "                else:\n",
    "                    x = torch.cat([x, torch.tensor([[next_char]], device=device)], dim=1)\n",
    "                \n",
    "                current_position += 1\n",
    "\n",
    "        # Convert result back to string\n",
    "        result = expression[:eq_position + 1]\n",
    "        result += ''.join(id_to_char[idx] for idx in generated_chars \n",
    "                         if idx not in [char_to_id['<eos>'], char_to_id['<pad>']])\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(2)\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = CharRNN(vocab_size,\n",
    "                embed_dim,\n",
    "                hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss(ignore_index=char_to_id['<pad>'])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "1. The outer `for` loop controls the `epoch`\n",
    "    1. The inner `for` loop uses `data_loader` to retrieve batches.\n",
    "        1. Pass the batch to the `model` for training.\n",
    "        2. Compare the predicted results `batch_pred_y` with the true labels `batch_y` using Cross Entropy to calculate the loss `loss`\n",
    "        3. Use `loss.backward` to automatically compute the gradients.\n",
    "        4. Use `torch.nn.utils.clip_grad_value_` to limit the gradient values between `-grad_clip` &lt; and &lt; `grad_clip`.\n",
    "        5. Use `optimizer.step()` to update the model (backpropagation).\n",
    "2.  After every `1000` batches, output the current loss to monitor whether it is converging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import math\n",
    "\n",
    "def validate_model(model, dataloader, device):\n",
    "    \"\"\"\n",
    "    Validates the model one expression at a time to ensure maximum accuracy\n",
    "    \n",
    "    Args:\n",
    "        model: The model to validate\n",
    "        dataloader: DataLoader containing validation data\n",
    "        device: Device to run the model on\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    matched = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        bar = tqdm(enumerate(dataloader), total=len(dataloader), desc=\"Validation\")\n",
    "        \n",
    "        for _, (batch_x, batch_y, batch_x_lens, batch_y_lens) in bar:\n",
    "            # Process each example in the batch individually\n",
    "            for i in range(batch_x.size(0)):\n",
    "                # Extract single expression\n",
    "                expr_tokens = [id_to_char[idx.item()] for idx in batch_x[i] \n",
    "                             if idx.item() not in [char_to_id['<pad>'], char_to_id['<eos>']]]\n",
    "                expr = ''.join(expr_tokens)\n",
    "                eq_idx = expr.find('=')\n",
    "                \n",
    "                if eq_idx != -1:\n",
    "                    # Get input expression up to equals sign\n",
    "                    input_expr = expr[:eq_idx + 1]\n",
    "                    \n",
    "                    # Get true answer\n",
    "                    true_tokens = [id_to_char[idx.item()] for idx in batch_y[i]\n",
    "                                if idx.item() not in [char_to_id['<pad>'], char_to_id['<eos>']]]\n",
    "                    true_answer = ''.join(true_tokens)\n",
    "                    \n",
    "                    # Generate prediction for single expression\n",
    "                    try:\n",
    "                        prediction = model.generator(input_expr)\n",
    "                        eq_idx = prediction.find('=')\n",
    "                        if eq_idx != -1:\n",
    "                            pred_answer = prediction[eq_idx + 1:].strip()\n",
    "                            true_answer = true_answer.strip()\n",
    "                            \n",
    "                            if pred_answer == true_answer:\n",
    "                                matched += 1\n",
    "                            total += 1\n",
    "                            \n",
    "                            # Update progress bar\n",
    "                            if total > 0:\n",
    "                                bar.set_postfix({\n",
    "                                    'accuracy': f\"{matched/total:.4f}\",\n",
    "                                })\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error processing expression {input_expr}: {str(e)}\")\n",
    "                        continue\n",
    "    \n",
    "    final_accuracy = matched/total if total > 0 else 0\n",
    "    print(f\"\\nFinal Accuracy: {final_accuracy:.4f}\")\n",
    "    print(f\"Correct: {matched}/{total}\")\n",
    "    return final_accuracy\n",
    "\n",
    "# Training loop\n",
    "def train_model(model, train_loader, eval_loader, criterion, optimizer, \n",
    "                device, epochs, grad_clip):\n",
    "    \n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        bar = tqdm(train_loader, desc=f\"Train epoch {epoch}\")\n",
    "        \n",
    "        for i, (batch_x, batch_y, batch_x_lens, batch_y_lens) in enumerate(bar):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            batch_pred_y = model(batch_x.to(device), batch_x_lens)\n",
    "            batch_pred_y = batch_pred_y[:, :batch_y.size(1), :].contiguous().view(-1, vocab_size)\n",
    "            batch_y = batch_y.to(device).contiguous().view(-1)\n",
    "            \n",
    "            # Calculate loss and backpropagate\n",
    "            loss = criterion(batch_pred_y, batch_y)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Update progress bar every 50 iterations\n",
    "            if i % 50 == 0:\n",
    "                bar.set_postfix(loss=loss.item())\n",
    "        \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 1: 100%|██████████| 9255/9255 [02:47<00:00, 55.30it/s, loss=0.268]\n",
      "Train epoch 2: 100%|██████████| 9255/9255 [02:47<00:00, 55.10it/s, loss=0.109] \n",
      "Train epoch 3: 100%|██████████| 9255/9255 [02:49<00:00, 54.67it/s, loss=0.077] \n",
      "Train epoch 4: 100%|██████████| 9255/9255 [02:44<00:00, 56.13it/s, loss=0.0688]\n",
      "Train epoch 5: 100%|██████████| 9255/9255 [02:45<00:00, 56.07it/s, loss=0.0433]\n",
      "Train epoch 6: 100%|██████████| 9255/9255 [02:44<00:00, 56.39it/s, loss=0.0543]\n",
      "Train epoch 7: 100%|██████████| 9255/9255 [02:42<00:00, 56.91it/s, loss=0.0291]\n",
      "Train epoch 8: 100%|██████████| 9255/9255 [02:42<00:00, 56.99it/s, loss=0.0414]\n",
      "Train epoch 9: 100%|██████████| 9255/9255 [02:44<00:00, 56.33it/s, loss=0.0333]\n",
      "Train epoch 10: 100%|██████████| 9255/9255 [02:42<00:00, 57.09it/s, loss=0.0174] \n"
     ]
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "model = train_model(\n",
    "    model=model,\n",
    "    train_loader=dl_train,\n",
    "    eval_loader=dl_eval,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    epochs=epochs,\n",
    "    grad_clip=grad_clip\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 1029/1029 [50:11<00:00,  2.93s/it, accuracy=0.9577]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Accuracy: 0.9577\n",
      "Correct: 252113/263250\n",
      "Final Score: 0.9576942070275404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "score = validate_model(model, dl_eval, device)\n",
    "print(f'Final Score: {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "import time\n",
    "\n",
    "date = time.strftime(\"%Y%m%d\")\n",
    "torch.save(model.state_dict(), f'{date}_{score}.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation\n",
    "Use `model.generator` and provide an initial character to automatically generate a sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_62792\\794600912.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_name))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model\n",
    "model_name = '20241113_0.9576942070275404.pth'\n",
    "model = CharRNN(vocab_size, embed_dim, hidden_dim)\n",
    "model.load_state_dict(torch.load(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10*35*26=9100\n"
     ]
    }
   ],
   "source": [
    "model = model.to('cpu')\n",
    "\n",
    "print(\"\".join(model.generator('10*35*26=')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
